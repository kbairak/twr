-- =============================================================================
-- CACHE TABLES AND REFRESH FUNCTIONS (Jinja2 Template)
-- =============================================================================
-- This migration creates cache infrastructure for multiple granularities.
-- For each granularity defined in granularities.py:
-- - Cache tables for pre-computed timeline data
-- - Timestamp indexes for efficient retention DELETE and MAX(timestamp) lookups
-- - Refresh function with optional retention policy
-- =============================================================================

{% for g in GRANULARITIES %}
-- =============================================================================
-- {{ g.suffix }} GRANULARITY CACHE
-- Cache retention: {{ g.cache_retention or 'indefinite' }}
-- =============================================================================

-- Cache table ({{ g.suffix }} granularity): stores pre-computed timeline data for performance
-- Acts like a materialized view but supports incremental updates
CREATE TABLE user_product_timeline_cache_{{ g.suffix }} (
    user_id UUID NOT NULL,
    product_id UUID NOT NULL,
    "timestamp" TIMESTAMPTZ NOT NULL,
    holdings NUMERIC(20, 6),
    net_deposits NUMERIC(20, 6),
    current_price NUMERIC(20, 6),
    current_value NUMERIC(20, 6),
    current_twr NUMERIC(20, 6),

    PRIMARY KEY (user_id, product_id, timestamp)
);

-- Cache table for user-level timeline ({{ g.suffix }} granularity, aggregated across products)
CREATE TABLE user_timeline_cache_{{ g.suffix }} (
    user_id UUID NOT NULL,
    "timestamp" TIMESTAMPTZ NOT NULL,
    total_net_deposits NUMERIC(20, 6),
    total_value NUMERIC(20, 6),
    value_weighted_twr NUMERIC(20, 6),
    PRIMARY KEY (user_id, timestamp)
);

-- Timestamp indexes for efficient retention DELETE and MAX(timestamp) lookups
-- Descending order optimizes for MAX(timestamp) queries (reads from end of index)
CREATE INDEX idx_user_product_timeline_cache_{{ g.suffix }}_timestamp
    ON user_product_timeline_cache_{{ g.suffix }} (timestamp DESC);

CREATE INDEX idx_user_timeline_cache_{{ g.suffix }}_timestamp
    ON user_timeline_cache_{{ g.suffix }} (timestamp DESC);

-- Function to incrementally refresh the cache ({{ g.suffix }} granularity)
-- Optimized to compute user_product_timeline_base_{{ g.suffix }} only once and use it for both caches
CREATE OR REPLACE FUNCTION refresh_timeline_cache_{{ g.suffix }}() RETURNS void AS $$
DECLARE
    v_watermark TIMESTAMPTZ;
    v_new_watermark TIMESTAMPTZ;
    v_now TIMESTAMPTZ;
BEGIN
    -- Capture current time once for consistency across all operations
    v_now := NOW();
{% if g.cache_retention %}
    -- Apply retention policy: delete old cache entries ({{ g.cache_retention }})
    -- Uses timestamp index for efficient deletion
    DELETE FROM user_product_timeline_cache_{{ g.suffix }}
    WHERE timestamp < v_now - INTERVAL '{{ g.cache_retention }}';

    DELETE FROM user_timeline_cache_{{ g.suffix }}
    WHERE timestamp < v_now - INTERVAL '{{ g.cache_retention }}';

{% endif %}
    -- Get current watermark from cache table (uses timestamp index for fast MAX lookup)
    SELECT MAX(timestamp) INTO v_watermark
    FROM user_product_timeline_cache_{{ g.suffix }};

    -- Handle empty cache case
    v_watermark := COALESCE(v_watermark, '1970-01-01'::TIMESTAMPTZ);

    -- Determine new watermark (max timestamp from actual data)
    SELECT MAX(timestamp) INTO v_new_watermark FROM user_product_timeline_base_{{ g.suffix }};

    -- If there's no data, use current time
    IF v_new_watermark IS NULL THEN
        v_new_watermark := now();
    END IF;

    -- Compute product timeline data ONCE and use it for both caches
    -- This avoids computing user_product_timeline_base_{{ g.suffix }} twice
    WITH product_timeline_data AS (
        SELECT user_id,
               product_id,
               timestamp,
               holdings,
               net_deposits,
               current_price,
               current_value,
               current_twr
        FROM user_product_timeline_base_{{ g.suffix }}
        WHERE timestamp > v_watermark
          AND timestamp <= v_new_watermark
{% if g.cache_retention %}
          -- Only cache data within retention window to avoid inserting data we'll immediately delete
          AND timestamp >= v_now - INTERVAL '{{ g.cache_retention }}'
{% endif %}
    ),
    product_insert AS (
        -- Insert into product-level cache ({{ g.suffix }} granularity)
        INSERT INTO user_product_timeline_cache_{{ g.suffix }}
        SELECT * FROM product_timeline_data
        ON CONFLICT DO NOTHING
        RETURNING 1
    )
    -- Insert into user-level cache by aggregating the product timeline data ({{ g.suffix }} granularity)
    INSERT INTO user_timeline_cache_{{ g.suffix }}
    SELECT
        user_id,
        timestamp,
        SUM(net_deposits) AS total_net_deposits,
        SUM(current_value) AS total_value,
        CASE
            WHEN SUM(current_value) > 0
            THEN SUM(current_twr * current_value) / SUM(current_value)
            ELSE 0
        END AS value_weighted_twr
    FROM product_timeline_data
    GROUP BY user_id, timestamp
    ON CONFLICT DO NOTHING;

    RAISE NOTICE '{{ g.suffix }} cache refreshed. Cached data up to: %', v_new_watermark;
END;
$$ LANGUAGE plpgsql;

{% endfor %}
